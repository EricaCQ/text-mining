{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc78294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Erica.Carneiro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Library needed\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from __future__ import division  # Python 2 users only\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.book import *\n",
    "import io\n",
    "from nltk.corpus import machado, mac_morpho, floresta, genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c4d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f82519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function using concordance from NLTK to find n-grams instead of unigrams\n",
    "def n_concordance_tokenised(text,phrase,left_margin=5,right_margin=5):\n",
    "    #concordance replication via https://simplypython.wordpress.com/2014/03/14/saving-output-of-nltk-text-concordance/\n",
    "    phraseList=phrase.split(' ')\n",
    " \n",
    "    c = nltk.ConcordanceIndex(text.tokens, key = lambda s: s.lower())\n",
    " \n",
    "    #Find the offset for each token in the phrase\n",
    "    offsets=[c.offsets(x) for x in phraseList]\n",
    "    offsets_norm=[]\n",
    "    #For each token in the phraselist, find the offsets and rebase them to the start of the phrase\n",
    "    for i in range(len(phraseList)):\n",
    "        offsets_norm.append([x-i for x in offsets[i]])\n",
    "    #Offset of a phrase found if the rebased values are intersected\n",
    "    #--\n",
    "    # http://stackoverflow.com/a/3852792/454773\n",
    "    #the intersection method with arbitrary amount of arguments\n",
    "    #result = set(d[0]).intersection(*d[1:])\n",
    "    #--\n",
    "    intersects=set(offsets_norm[0]).intersection(*offsets_norm[1:])\n",
    " \n",
    "    concordance_txt = ([text.tokens[list(map(lambda x: x-left_margin if (x-left_margin)>0 else 0,[offset]))[0]:offset+len(phraseList)+right_margin] for offset in intersects])\n",
    " \n",
    "    outputs=[''.join([x+' ' for x in con_sub]) for con_sub in concordance_txt]\n",
    "    return outputs\n",
    " \n",
    "def n_concordance(txt,phrase,left_margin=5,right_margin=5):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    text = nltk.Text(tokens)\n",
    " \n",
    "    return n_concordance_tokenised(text,phrase,left_margin=left_margin,right_margin=right_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef87dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open your text\n",
    "with open('you_text.txt', 'r', encoding =\"utf8\") as file1:\n",
    "    data1 = file1.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize text file\n",
    "tokens = word_tokenize(data1)\n",
    "print(tokens)\n",
    "textList = Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call n_Concordance functions\n",
    "n_concordance_tokenised(textList, 'Agente Fiduci√°rio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfabb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
